{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3b326-77f2-480f-a698-12e40b83aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### original code on which the test has been run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91727\\OneDrive\\Desktop\\hodson\\vishesh codes and files\\hodson.csv\", low_memory=False)\n",
    "\n",
    "# Step 2: Data Preprocessing (Handling Missing Values)\n",
    "# Example: Fill missing numerical columns with median and categorical columns with mode\n",
    "df['Assessed Value'] = df['Assessed Value'].fillna(df['Assessed Value'].median())\n",
    "df['Sale Amount'] = df['Sale Amount'].fillna(df['Sale Amount'].median())\n",
    "df['Sales Ratio'] = df['Sales Ratio'].fillna(df['Sales Ratio'].median())\n",
    "df['Town'] = df['Town'].fillna(df['Town'].mode()[0])\n",
    "df['Property Type'] = df['Property Type'].fillna(df['Property Type'].mode()[0])\n",
    "df['Residential Type'] = df['Residential Type'].fillna(df['Residential Type'].mode()[0])\n",
    "\n",
    "# Step 3: Feature Engineering (creating Likely_to_Sell_Flag from remarks)\n",
    "keywords = ['ESTATE SALE', 'SHORT SALE', 'RENOVATED', 'TOTAL RENOVATION', 'MUST SELL', 'MOVING SALE', 'DISTRESSED']\n",
    "\n",
    "def flag_likely_to_sell(remarks):\n",
    "    if pd.isna(remarks) or remarks.strip() == \"\":\n",
    "        return 0\n",
    "    remarks = str(remarks).upper()\n",
    "    if any(keyword in remarks for keyword in keywords):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['Likely_to_Sell_Flag'] = df['Assessor Remarks'].apply(flag_likely_to_sell) | df['OPM remarks'].apply(flag_likely_to_sell)\n",
    "\n",
    "# Step 4: Feature and Target Selection\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', 'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "y = df['Likely_to_Sell_Flag']\n",
    "\n",
    "df.head(10)\n",
    "# Step 5: Handle Class Imbalance with SMOTE (Optional)\n",
    "# Step 1: Drop unnecessary columns (already done earlier)\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', \n",
    "                     'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# Replace missing categorical values with 'Unknown'\n",
    "X['Town'] = X['Town'].fillna('Unknown')\n",
    "X['Property Type'] = X['Property Type'].fillna('Unknown')\n",
    "X['Residential Type'] = X['Residential Type'].fillna('Unknown')\n",
    "\n",
    "# Replace missing numerical values with median\n",
    "X['Assessed Value'] = X['Assessed Value'].fillna(X['Assessed Value'].median())\n",
    "X['Sale Amount'] = X['Sale Amount'].fillna(X['Sale Amount'].median())\n",
    "X['Sales Ratio'] = X['Sales Ratio'].fillna(X['Sales Ratio'].median())\n",
    "\n",
    "# Step 3: Convert categorical columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 6: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Step 7: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 8: Define Models to Evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine (SVM)\": SVC(random_state=42),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Step 9: Function to Evaluate Models\n",
    "def evaluate_models(X, y):\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of {model_name}: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        \n",
    "# Step 10: Run the Model Evaluation\n",
    "evaluate_models(X_resampled, y_resampled)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91be7304-af4c-407d-8406-cbdafbe377fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118b20b7-199a-4d10-9ff6-ddabc471654d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91727\\OneDrive\\Desktop\\hodson\\vishesh codes and files\\hodson.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299d205f-bb39-4132-af22-5b6dfa8a8cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing (Handling Missing Values)\n",
    "# Example: Fill missing numerical columns with median and categorical columns with mode\n",
    "df['Assessed Value'] = df['Assessed Value'].fillna(df['Assessed Value'].median())\n",
    "df['Sale Amount'] = df['Sale Amount'].fillna(df['Sale Amount'].median())\n",
    "df['Sales Ratio'] = df['Sales Ratio'].fillna(df['Sales Ratio'].median())\n",
    "df['Town'] = df['Town'].fillna(df['Town'].mode()[0])\n",
    "df['Property Type'] = df['Property Type'].fillna(df['Property Type'].mode()[0])\n",
    "df['Residential Type'] = df['Residential Type'].fillna(df['Residential Type'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44be2f4-9e29-4e1a-bb30-1f9ec096218e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering (creating Likely_to_Sell_Flag from remarks)\n",
    "keywords = ['ESTATE SALE', 'SHORT SALE', 'RENOVATED', 'TOTAL RENOVATION', 'MUST SELL', 'MOVING SALE', 'DISTRESSED']\n",
    "\n",
    "def flag_likely_to_sell(remarks):\n",
    "    if pd.isna(remarks) or remarks.strip() == \"\":\n",
    "        return 0\n",
    "    remarks = str(remarks).upper()\n",
    "    if any(keyword in remarks for keyword in keywords):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['Likely_to_Sell_Flag'] = df['Assessor Remarks'].apply(flag_likely_to_sell) | df['OPM remarks'].apply(flag_likely_to_sell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b88655d-e810-4b1b-a9df-8255dae4c774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Feature and Target Selection\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', 'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "y = df['Likely_to_Sell_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe4e5aa-ee4a-4129-9fd3-2b383bccdb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>List Year</th>\n",
       "      <th>Date Recorded</th>\n",
       "      <th>Town</th>\n",
       "      <th>Address</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Sale Amount</th>\n",
       "      <th>Sales Ratio</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Residential Type</th>\n",
       "      <th>Non Use Code</th>\n",
       "      <th>Assessor Remarks</th>\n",
       "      <th>OPM remarks</th>\n",
       "      <th>Location</th>\n",
       "      <th>Likely_to_Sell_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190176</td>\n",
       "      <td>2019</td>\n",
       "      <td>01-06-2020</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>236 ROOSEVELT DR</td>\n",
       "      <td>52570</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>25 - Other</td>\n",
       "      <td>2 PROPERTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-73.1376 41.35798)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190711</td>\n",
       "      <td>2019</td>\n",
       "      <td>29-04-2020</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>11 COLUMBINE LN</td>\n",
       "      <td>311630</td>\n",
       "      <td>555000.0</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-31-126-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190509</td>\n",
       "      <td>2019</td>\n",
       "      <td>01-09-2020</td>\n",
       "      <td>Wethersfield</td>\n",
       "      <td>3 WHEELER RD</td>\n",
       "      <td>162230</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>10 - A Will</td>\n",
       "      <td>ESTATE SALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20058</td>\n",
       "      <td>2020</td>\n",
       "      <td>01-06-2021</td>\n",
       "      <td>Barkhamsted</td>\n",
       "      <td>46 RATLUM MTN RD</td>\n",
       "      <td>203530</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>0.490434</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003 COLONIAL, 2140 SFLA, 2.99 AC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200207</td>\n",
       "      <td>2020</td>\n",
       "      <td>23-11-2020</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>BROAD PLACE LOTS 225-6 AND 224</td>\n",
       "      <td>8400</td>\n",
       "      <td>38500.0</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>25 - Other</td>\n",
       "      <td>MULTIPLE LOT SALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-72.90406 41.66996)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20093</td>\n",
       "      <td>2020</td>\n",
       "      <td>02-02-2021</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>57 ROCK RD</td>\n",
       "      <td>194670</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>0.707800</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>10 - A Will</td>\n",
       "      <td>ESTATE SALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200142</td>\n",
       "      <td>2020</td>\n",
       "      <td>04-03-2021</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>SQUIRREL TR</td>\n",
       "      <td>35600</td>\n",
       "      <td>42750.0</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R/C/8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200110</td>\n",
       "      <td>2020</td>\n",
       "      <td>14-01-2021</td>\n",
       "      <td>Cromwell</td>\n",
       "      <td>25 MIDWAY DR</td>\n",
       "      <td>128200</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Condo</td>\n",
       "      <td>25 - Other</td>\n",
       "      <td>BAA OVERRIDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200485</td>\n",
       "      <td>2020</td>\n",
       "      <td>13-01-2021</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>27 CROWS NEST LA 6A</td>\n",
       "      <td>110300</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Condo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L15008-61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200915</td>\n",
       "      <td>2020</td>\n",
       "      <td>10-05-2021</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>51 OLD BOSTON POST RD</td>\n",
       "      <td>191600</td>\n",
       "      <td>394000.0</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H22043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number  List Year Date Recorded          Town  \\\n",
       "0         190176       2019    01-06-2020       Seymour   \n",
       "1         190711       2019    29-04-2020       Norwalk   \n",
       "2         190509       2019    01-09-2020  Wethersfield   \n",
       "3          20058       2020    01-06-2021   Barkhamsted   \n",
       "4         200207       2020    23-11-2020       Bristol   \n",
       "5          20093       2020    02-02-2021    Burlington   \n",
       "6         200142       2020    04-03-2021      Coventry   \n",
       "7         200110       2020    14-01-2021      Cromwell   \n",
       "8         200485       2020    13-01-2021       Danbury   \n",
       "9         200915       2020    10-05-2021       Danbury   \n",
       "\n",
       "                          Address  Assessed Value  Sale Amount  Sales Ratio  \\\n",
       "0                236 ROOSEVELT DR           52570      75000.0     0.700900   \n",
       "1                 11 COLUMBINE LN          311630     555000.0     0.561500   \n",
       "2                    3 WHEELER RD          162230     225000.0     0.721000   \n",
       "3                46 RATLUM MTN RD          203530     415000.0     0.490434   \n",
       "4  BROAD PLACE LOTS 225-6 AND 224            8400      38500.0     0.218100   \n",
       "5                      57 ROCK RD          194670     275000.0     0.707800   \n",
       "6                     SQUIRREL TR           35600      42750.0     0.832700   \n",
       "7                    25 MIDWAY DR          128200     208000.0     0.616300   \n",
       "8             27 CROWS NEST LA 6A          110300     195000.0     0.565600   \n",
       "9           51 OLD BOSTON POST RD          191600     394000.0     0.486200   \n",
       "\n",
       "   Property Type Residential Type Non Use Code  \\\n",
       "0  Single Family    Single Family   25 - Other   \n",
       "1  Single Family    Single Family          NaN   \n",
       "2  Single Family    Single Family  10 - A Will   \n",
       "3    Residential    Single Family          NaN   \n",
       "4    Vacant Land    Single Family   25 - Other   \n",
       "5    Residential    Single Family  10 - A Will   \n",
       "6    Vacant Land    Single Family          NaN   \n",
       "7    Residential            Condo   25 - Other   \n",
       "8    Residential            Condo          NaN   \n",
       "9    Residential    Single Family          NaN   \n",
       "\n",
       "                    Assessor Remarks OPM remarks                    Location  \\\n",
       "0                       2 PROPERTIES         NaN   POINT (-73.1376 41.35798)   \n",
       "1                         5-31-126-0         NaN                         NaN   \n",
       "2                        ESTATE SALE         NaN                         NaN   \n",
       "3  2003 COLONIAL, 2140 SFLA, 2.99 AC         NaN                         NaN   \n",
       "4                  MULTIPLE LOT SALE         NaN  POINT (-72.90406 41.66996)   \n",
       "5                        ESTATE SALE         NaN                         NaN   \n",
       "6                              R/C/8         NaN                         NaN   \n",
       "7                       BAA OVERRIDE         NaN                         NaN   \n",
       "8                          L15008-61         NaN                         NaN   \n",
       "9                             H22043         NaN                         NaN   \n",
       "\n",
       "   Likely_to_Sell_Flag  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    1  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfce244-08d3-4b8b-8c2a-cb2c6050f5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Drop unnecessary columns (already done earlier)\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', \n",
    "                     'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# Replace missing categorical values with 'Unknown'\n",
    "X['Town'] = X['Town'].fillna('Unknown')\n",
    "X['Property Type'] = X['Property Type'].fillna('Unknown')\n",
    "X['Residential Type'] = X['Residential Type'].fillna('Unknown')\n",
    "\n",
    "# Replace missing numerical values with median\n",
    "X['Assessed Value'] = X['Assessed Value'].fillna(X['Assessed Value'].median())\n",
    "X['Sale Amount'] = X['Sale Amount'].fillna(X['Sale Amount'].median())\n",
    "X['Sales Ratio'] = X['Sales Ratio'].fillna(X['Sales Ratio'].median())\n",
    "\n",
    "# Step 3: Convert categorical columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3675bc-6939-4648-b3ab-bbf6c163eb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf17e363-7036-4596-93fa-db83837dc020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 7: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb7a2e1-f6c8-4b0d-9fe3-c9c2d504cc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Define Models to Evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine (SVM)\": SVC(random_state=42),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0630b8-4ee2-4a86-b545-c829fd9c248a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 9: Function to Evaluate Models\n",
    "def evaluate_models(X, y):\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of {model_name}: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de3c13c-dc24-4f8f-a566-83b882832143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Logistic Regression...\n",
      "Accuracy of Logistic Regression: 93.01%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93     27312\n",
      "           1       0.98      0.87      0.93     27310\n",
      "\n",
      "    accuracy                           0.93     54622\n",
      "   macro avg       0.94      0.93      0.93     54622\n",
      "weighted avg       0.94      0.93      0.93     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26917   395]\n",
      " [ 3421 23889]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Random Forest...\n",
      "Accuracy of Random Forest: 95.18%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     27312\n",
      "           1       0.96      0.94      0.95     27310\n",
      "\n",
      "    accuracy                           0.95     54622\n",
      "   macro avg       0.95      0.95      0.95     54622\n",
      "weighted avg       0.95      0.95      0.95     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26252  1060]\n",
      " [ 1572 25738]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Support Vector Machine (SVM)...\n",
      "Accuracy of Support Vector Machine (SVM): 92.99%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     27312\n",
      "           1       0.97      0.88      0.93     27310\n",
      "\n",
      "    accuracy                           0.93     54622\n",
      "   macro avg       0.93      0.93      0.93     54622\n",
      "weighted avg       0.93      0.93      0.93     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26679   633]\n",
      " [ 3197 24113]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating K-Nearest Neighbors (KNN)...\n",
      "Accuracy of K-Nearest Neighbors (KNN): 93.04%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     27312\n",
      "           1       0.95      0.91      0.93     27310\n",
      "\n",
      "    accuracy                           0.93     54622\n",
      "   macro avg       0.93      0.93      0.93     54622\n",
      "weighted avg       0.93      0.93      0.93     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26058  1254]\n",
      " [ 2549 24761]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Decision Tree...\n",
      "Accuracy of Decision Tree: 92.13%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     27312\n",
      "           1       0.91      0.93      0.92     27310\n",
      "\n",
      "    accuracy                           0.92     54622\n",
      "   macro avg       0.92      0.92      0.92     54622\n",
      "weighted avg       0.92      0.92      0.92     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24818  2494]\n",
      " [ 1806 25504]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Naive Bayes...\n",
      "Accuracy of Naive Bayes: 62.86%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.32      0.46     27312\n",
      "           1       0.58      0.94      0.72     27310\n",
      "\n",
      "    accuracy                           0.63     54622\n",
      "   macro avg       0.71      0.63      0.59     54622\n",
      "weighted avg       0.71      0.63      0.59     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8666 18646]\n",
      " [ 1638 25672]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Gradient Boosting...\n",
      "Accuracy of Gradient Boosting: 86.42%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87     27312\n",
      "           1       0.90      0.82      0.86     27310\n",
      "\n",
      "    accuracy                           0.86     54622\n",
      "   macro avg       0.87      0.86      0.86     54622\n",
      "weighted avg       0.87      0.86      0.86     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24900  2412]\n",
      " [ 5004 22306]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "Accuracy of AdaBoost: 85.34%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86     27312\n",
      "           1       0.87      0.83      0.85     27310\n",
      "\n",
      "    accuracy                           0.85     54622\n",
      "   macro avg       0.85      0.85      0.85     54622\n",
      "weighted avg       0.85      0.85      0.85     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23882  3430]\n",
      " [ 4576 22734]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating Ridge Classifier...\n",
      "Accuracy of Ridge Classifier: 91.42%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     27312\n",
      "           1       1.00      0.83      0.91     27310\n",
      "\n",
      "    accuracy                           0.91     54622\n",
      "   macro avg       0.93      0.91      0.91     54622\n",
      "weighted avg       0.93      0.91      0.91     54622\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27312     0]\n",
      " [ 4684 22626]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Run the Model Evaluation\n",
    "evaluate_models(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b599dc-10bb-41db-bb8d-617aeb33ece1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###code with modification which i will run later\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter  # <CHANGE>\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91727\\OneDrive\\Desktop\\hodson\\vishesh codes and files\\hodson.csv\", low_memory=False)\n",
    "\n",
    "# Step 2: Data Preprocessing (Handling Missing Values)\n",
    "# Example: Fill missing numerical columns with median and categorical columns with mode\n",
    "df['Assessed Value'] = df['Assessed Value'].fillna(df['Assessed Value'].median())\n",
    "df['Sale Amount'] = df['Sale Amount'].fillna(df['Sale Amount'].median())\n",
    "df['Sales Ratio'] = df['Sales Ratio'].fillna(df['Sales Ratio'].median())\n",
    "df['Town'] = df['Town'].fillna(df['Town'].mode()[0])\n",
    "df['Property Type'] = df['Property Type'].fillna(df['Property Type'].mode()[0])\n",
    "df['Residential Type'] = df['Residential Type'].fillna(df['Residential Type'].mode()[0])\n",
    "\n",
    "# Step 3: Feature Engineering (creating Likely_to_Sell_Flag from remarks)\n",
    "keywords = ['ESTATE SALE', 'SHORT SALE', 'RENOVATED', 'TOTAL RENOVATION', 'MUST SELL', 'MOVING SALE', 'DISTRESSED']\n",
    "\n",
    "def flag_likely_to_sell(remarks):\n",
    "    if pd.isna(remarks) or remarks.strip() == \"\":\n",
    "        return 0\n",
    "    remarks = str(remarks).upper()\n",
    "    if any(keyword in remarks for keyword in keywords):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['Likely_to_Sell_Flag'] = df['Assessor Remarks'].apply(flag_likely_to_sell) | df['OPM remarks'].apply(flag_likely_to_sell)\n",
    "\n",
    "# Step 4: Feature and Target Selection\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', 'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "y = df['Likely_to_Sell_Flag']\n",
    "\n",
    "# Print dataset shapes before SMOTE\n",
    "print(f\"Dataset shape before SMOTE: {X.shape}, Target shape: {y.shape}\")  # <CHANGE>\n",
    "\n",
    "# Step 5: Handle Class Imbalance with SMOTE\n",
    "# Step 1: Drop unnecessary columns (already done earlier)\n",
    "X = df.drop(columns=['Likely_to_Sell_Flag', 'Serial Number', 'Address', 'Date Recorded', \n",
    "                     'Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'])\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# Replace missing categorical values with 'Unknown'\n",
    "X['Town'] = X['Town'].fillna('Unknown')\n",
    "X['Property Type'] = X['Property Type'].fillna('Unknown')\n",
    "X['Residential Type'] = X['Residential Type'].fillna('Unknown')\n",
    "\n",
    "# Replace missing numerical values with median\n",
    "X['Assessed Value'] = X['Assessed Value'].fillna(X['Assessed Value'].median())\n",
    "X['Sale Amount'] = X['Sale Amount'].fillna(X['Sale Amount'].median())\n",
    "X['Sales Ratio'] = X['Sales Ratio'].fillna(X['Sales Ratio'].median())\n",
    "\n",
    "# Step 3: Convert categorical columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print class distributions after SMOTE\n",
    "print(f\"Class distribution before SMOTE: {Counter(y)}\")  # <CHANGE>\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_resampled)}\")  # <CHANGE>\n",
    "\n",
    "# Step 6: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check scaling\n",
    "print(\"First 5 rows of scaled training data:\")  # <CHANGE>\n",
    "print(X_train_scaled[:5])  # <CHANGE>\n",
    "\n",
    "# Step 8: Define Models to Evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine (SVM)\": SVC(random_state=42),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Step 9: Function to Evaluate Models\n",
    "results = {}  # <CHANGE>\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")  # <CHANGE>\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Save results\n",
    "    results[model_name] = {  # <CHANGE>\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
    "    }\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Save evaluation results to JSON\n",
    "import json  # <CHANGE>\n",
    "with open(\"model_evaluation_results.json\", \"w\") as f:  # <CHANGE>\n",
    "    json.dump(results, f)  # <CHANGE>\n",
    "    \n",
    "# Feature importance analysis\n",
    "feature_importances = RandomForestClassifier().fit(X_train_scaled, y_train).feature_importances_  # <CHANGE>\n",
    "important_features = pd.Series(feature_importances, index=X.columns).sort_values(ascending=False)  # <CHANGE>\n",
    "print(\"Top 10 important features:\")  # <CHANGE>\n",
    "print(important_features.head(10))  # <CHANGE>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
